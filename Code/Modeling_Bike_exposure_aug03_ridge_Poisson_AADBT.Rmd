---
title: "Bike Esposure Modeling_UC_Berkeley"
author: "Md Mintu Miah, Ph.D."
date: "2023-01-25"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# read necessary library
rm(list = ls())

if (!require("pacman")) install.packages("pacman")
p_load(dplyr)
#p_load(MASS)
p_load(sandwich)
#library(mgcv)
p_load(lmtest)
p_load(caret)
p_load(AER)
p_load(cvTools)
p_load(ggplot2)
p_load(readr)
if(!require("glmnet")) install.packages("glmnet")
#library(plyr)
#library(glmmTMB)

```




```{r}
##### FUNCTION DEFINITIONS #####
cvstats <- function (p, k, r=1) {
  n = k * r
  stats <- p %>%
    group_by(Resample) %>%
    summarize(rmse=sqrt(mean((pred - obs) ^ 2)),
              mae=mean(abs(pred - obs)),
              mape=mean(abs((pred - obs) / obs * 100)),
              r2=cor(pred, obs,use="complete.obs")^2,
              mfr2=((sum()))) %>%
    summarize(mean(rmse), se_rmse=sd(rmse)/sqrt(n), mean(mae), 
              se_mae=sd(mae)/sqrt(n), mean(mape), se_mape=sd(mape)/sqrt(n),
              mean(r2), se_r2=sd(r2)/sqrt(n))
  stats
}

cvstats.tertile <- function(p, k, r=1) {
  # Note: assignment is stochastic at boundaries, thus the fractional n's
  n_cv = k * r  # total out of sample predictions
  
  stats <- p %>% 
    mutate(tertile = ntile(obs, 3)) %>%
    group_by(Resample, tertile) %>%
    summarize(rmse=sqrt(mean((pred - obs) ^ 2)),
              mae=mean(abs(pred - obs)),
              mape=mean(abs((pred - obs) / obs * 100)),
              r2=cor(pred, obs, use="complete.obs")^2, n=n()) %>%
    group_by(tertile) %>%
    summarize(mean(rmse), se_rmse=sd(rmse)/sqrt(n_cv), mean(mae), 
              se_mae=sd(mae)/sqrt(n_cv), mean(mape), se_mape=sd(mape)/sqrt(n_cv),
              mean(r2), se_r2=sd(r2)/sqrt(n_cv), n=sum(n)/r)
  
  stats
}

cvstats.county <- function(m, d, k, r) {
  # for now group must be in select var list
  #n_cv = k * r
  
  p2 <- d %>% select(rowIndex, tdg_id, county, AADB) %>%
    inner_join(m$pred, by="rowIndex") 
  
  n_reg <- p2 %>%
    distinct(rowIndex, county) %>%
    group_by(county) %>%
    summarize(n=n())
  
  stats <- p2 %>% 
    group_by(Resample, county) %>%
    summarize(rmse=sqrt(mean((pred - obs) ^ 2)),
              mae=mean(abs(pred - obs)),
              mape=mean(abs((pred - obs) / obs * 100)),
              ae=mean(pred-obs),
              ape=mean((pred - obs) / obs * 100),
              r2=cor(pred, obs, use="complete.obs")^2,
              n=n()) %>%
    group_by(county) %>%
    summarize(mean(rmse), mean(mae), 
              mean(mape), mean(r2, na.rm=F)) %>%
    left_join(n_reg, by="county")
  
  stats
}

cvstats.pattern <- function(m, d, k, r) {
  # for now group must be in select var list
  p2 <- d %>% select(rowIndex, tdg_id, county, AADB, Leg) %>%
    inner_join(m$pred, by="rowIndex")
  
  stats <- p2 %>% 
    group_by(Leg) %>%
    summarize(rmse=sqrt(mean((pred - obs) ^ 2)),
              mae=mean(abs(pred - obs)),
              mape=mean(abs((pred - obs) / obs * 100)),
              avgpe=mean((pred - obs) / obs * 100),
              avgerr=mean(pred-obs))
  print(stats)
}

mf_r2 <- function(m) {
  # McFadden's pseudo-R2
  r2 <- 1 - (m$deviance / m$null.deviance)
  r2
}

summarize_model <- function(m, d, k, r, robust_se="HC3") {
  # m - model train/test results from caret package
  # k - number of Cv folds
  # r - number of fold repeats
  p <- m$pred
  print(cvstats(p, k, r))
  print(cvstats.tertile(p, k, r))
  print(cvstats.county(m, d, k, r))
  print(summary(m))
  print("")
  print(paste("McFadden's pseudo-R2 =", mf_r2(m$finalModel)))
  print("")
  print(coeftest(m$finalModel, 
                 vcov = vcovHC(m$finalModel, type=robust_se)))  # robust SEs 
}

plot_regions <- function(m, d, title="", scales="fixed") {
  p2 <- d %>% select(rowIndex, tdg_id, county, AADB, Leg) %>%
    inner_join(m$pred, by="rowIndex") %>%
    group_by(tdg_id, county, Leg) %>%
    summarize(avg_obs=mean(obs), avg_pred=mean(pred))
  
  p2 %>% ggplot(aes(x=avg_pred, y=avg_obs)) +
    geom_point(col="blue") +coord_flip(ylim = c(0,3300), xlim = c(0,3300))+
    geom_abline(intercept=0, slope=1, lty=2) +
    facet_wrap(~ county, scales=scales) +
    labs(x="mean predicted AADBT", y="observed AADBT") +
    ggtitle(title)
}


plot_all <- function(m, d, title="", label_outliers=0) {
  # label_outliers - label if avg err falls in top X pct of cases
  p2 <- d %>% select(rowIndex, tdg_id, county, AADB, Leg,year) %>%
    inner_join(m$pred, by="rowIndex") %>%
    group_by(tdg_id,county, Leg, year) %>%
    summarize(avg_obs=mean(obs), avg_pred=mean(pred)) %>%
    mutate(avg_err=mean(avg_pred - avg_obs)) 
    label_min <- quantile(abs(p2$avg_err), p=((100 - label_outliers) / 100))
  
  p2 %>% ggplot(aes(x=avg_pred, y=avg_obs, col=as.factor(county),
                    shape=as.factor(county))) +
    geom_abline(intercept=0, slope=1, lty=2) +
    geom_point(size=2.0, fill=NA) +coord_flip(ylim = c(0,3300), xlim = c(0, 3300))+
    labs(x="Mean predicted AADBT", y="Observed AADBT") + 
    geom_text(data=subset(p2, avg_err >= 0 & abs(avg_err) >= label_min),
              aes(avg_pred, avg_obs, label=substr(county, 1, 27)),
              nudge_y=30, size=3) +
    geom_text(data=subset(p2, avg_err < 0 & abs(avg_err) >= label_min),
              aes(avg_pred, avg_obs, label=substr(county, 1, 27)),
              nudge_y=-30, size=3) +
    ggtitle(title)
}

##### END FUNCTION DEFINITIONS #####
```

# read the data
```{r}
data=read.csv('D:/Bike Exposure/Modeling/updated_model_data_july3.csv')
data=subset(data, data$AADB>0)
#data$ATT.in.Thousands <- data$ATT/1000
#data$AADB <- round(data$ATT/365, digit=0)
#data$rowIndex <- seq.int(nrow(data))
#data$primary <- ifelse(data$fclass=='primary', 1, 0)
#data$secondary <- ifelse(data$fclass=='secondary', 1, 0)
#data$tertiary<- ifelse(data$fclass=='tertiary', 1, 0)
#data$residential<- ifelse(data$fclass=='residential', 1, 0)
#data$trunk<- ifelse(data$fclass=='trunk', 1, 0)
#data$secondary_link<- ifelse(data$fclass=='secondary_link', 1, 0)
#data$unclassified<- ifelse(data$fclass=='unclassified', 1, 0)
#data$speed_0_25=ifelse(data$speed<=25, 1, 0)
#data$speed_21_35=ifelse(dplyr::between(data$speed, 21, 35), 1, 0)
data$speed_less_than_30=ifelse(data$speed<30, 1, 0)
data$Speed_30_or_Above=ifelse(data$speed>29, 1, 0)
data$speed_less_than_25=ifelse(data$speed<25, 1, 0)
data$Speed_25_or_Above=ifelse(data$speed>24, 1, 0)
data$speed_less_than_20=ifelse(data$speed<20, 1, 0)
data$Speed_20_or_Above=ifelse(data$speed>19, 1, 0)
#data$Stv_commute_adb=(data$forward_commute_trip_count+data$reverse_commute_trip_count)/365
#data$Stv_leisure_adb=(data$forward_leisure_trip_count+data$reverse_leisure_trip_count)/365
#data$Stv_Ave_speed=data$forward_average_speed+data$reverse_average_speed
#data$path=ifelse(data$bike_facs=='Class I', 1, 0)
#data$bike_lane=ifelse(data$bike_facs=='Class II', 1, 0)
#data$bike_route=ifelse(data$bike_facs=='Class III', 1, 0)
#data$cycle_track=ifelse(data$bike_facs=='Class IV', 1, 0)
#data$trail=ifelse(data$bike_facs=='Class V', 1, 0)
#data$other=ifelse(data$bike_facs=='Class VI', 1, 0)
#data$Interstate=ifelse(data$fc_draft==1, 1, 0)
#data$Freeway=ifelse(data$fc_draft==2, 1, 0)
#data$Principal_Arterial=ifelse(data$fc_draft==3, 1, 0)
#data$Minor_Arterial=ifelse(data$fc_draft==4, 1, 0)
#data$Major_Collector=ifelse(data$fc_draft==5, 1, 0)
#data$Minor_Collector=ifelse(data$fc_draft==6, 1, 0)
#data$Local=ifelse(data$fc_draft==7, 1, 0)
#data[is.na(data)] <- 0
#write.csv(data,'D:/Bike Exposure/Modeling/Final_data_March31.csv')
#head(data,5)
```
`
```{r}
# Exclude the outlier based on Frank's suggested formula
ag1 <- aggregate(AADB ~ county, data, FUN=mean)
colnames(ag1)[colnames(ag1)=="AADB"] <- "Mean"
ag2 <- aggregate(AADB ~ county, data, FUN=sd)
colnames(ag2)[colnames(ag2)=="AADB"] <- "std"
data1=merge(ag1,ag2,by='county')
data2=merge(data,data1, by='county')
# now exclude the outlier
data2['outlier'] = (data2$AADB > (data2$Mean + 5 * data2$std))
data3=subset(data2, outlier==FALSE)
# Save data after removing outlier
write.csv(data3,'D:/Bike Exposure/Modeling/Model_clean_data_july23_AADBT.csv')
```

```{r}
min(data3$AADB)
```



```{r}
# save this updated data
#write.csv(u_data1,'D:/Bike Exposure/Modeling/Model_final_data.csv')
```




```{r}
# remove tha columns that have missing value
#data1=data %>% 
#  select(where(~!any(is.na(.))))
num_cols <- unlist(lapply(data3, is.numeric)) 
data4 <- data3[ , num_cols]  
#data1=data1 %>% dplyr::select(where(is.numeric))
#data1$rowIndex <- seq.int(nrow(data1))
data4
```


```{r}
data4[is.na(data4)] <- 0
z=cor(data4)
zdf <- as.data.frame((z))
zdf=subset(zdf,select=c(AADB))
zdf
```
```{r}
data[is.na(data)] <- 0
```




```{r}
# Set up train/test controller 
seed = 94704 
k = 10  # folds
r = 10  # repeats
set.seed(seed)  # note checked fairly stable w/ seed changes

# Note: eventually went back to caret w/ stratified folds 
train_control5 <- trainControl(method="repeatedcv", number=k, repeats=r,
                               savePredictions = TRUE)

```



```{r}
#check volume Bin
quantile(as.integer(data3$AADB), p=seq(0, 1, 1/3))
quantile(as.integer(data3$AADB), p=seq(0, 1, 1/3))
nrow(data3)
```
```{r}
# Change NA with Zero, otherwise model will exclude the data
data3=data3%>% replace(is.na(.), 0)
```

# Lets run Ridge regression to select the variables first

```{r}
#install.packages("tidyverse")
#library(tidyverse) 
#list.files(path = "../input")
#if(! require("ggplot2")) install.packages("ggplot2")
#if(!require(GGally))  install.packages("GGally")
#if(!require(psych)) install.packages("psych")
#if(!require(pls)) install.packages("pls")
#if(!require("tree")) install.packages("tree")
#if(!require("randomForest")) install.packages("randomForest")
#if(!require("caret")) install.packages("caret")
#if(!require("pROC")) install.packages("pROC")
#if(!require("MASS")) install.packages("MASS")
if(!require("glmnet")) install.packages("glmnet")
library(glmnet)
#library(MASS)
#library(pROC)
#library(caret)
#library(randomForest)
#library(tree)
#library(pls)
#library(psych)
#library(GGally)



# Set the plot size
if(!require(repr)) install.packages("repr")
library(repr)

fig <- function(width, heigth){
     options(repr.plot.width = width, repr.plot.height = heigth)
}
```

```{r}
colnames(data4)
```



```{r}
#list(colnames(data4))
data5=subset(data4,select=-c(X,ID,Lat,year,Long,
                             no_of_months_data_collected ,ATT.in.Million,matched_seg_id, segment_id,tdg_id                   ,lrs_cal_id , bikes_proh,seg_counter,fc_draft,adt_amt,rt_lanes_amt ,lt_lanes_amt,near_strava_id,index,ATT.in.Thousands,rowIndex,unclassified,std,
                             Mean,bgarea_t ,bgarea_q ,bgarea_h,bgcliparea_t,bgcliparea_q,bgcliparea_h,pctofbgarea_t,pctofbgarea_q,
                             pctofbgarea_h, ATT,primary                     
,secondary,tertiary,residential,trunk,secondary_link,unclassified,speed_21_35,speed_0_25,exist_ferry_h ))      
```




```{r}
X <- as.matrix(subset(data5,select=-c(AADB)))
y <- data5$AADB
```

```{r}
# when lambda=0, it is ridge regression
# when lambda=1, it is lasso regression
# when lambda between 1 and zero, it is elastic net
set.seed(1)
cv_lasso_lr_model = cv.glmnet(X, y, alpha = 1)
bestlam = cv_lasso_lr_model$lambda.min
cv_lasso_lr_model
par(mfrow=c(1,2))
fig(20, 8)
plot(cv_lasso_lr_model)
plot(cv_lasso_lr_model$glmnet.fit, 
     "lambda", label=FALSE)
```



```{r}
lasso_lr_model = glmnet(X, y, alpha =1, lambda = bestlam)
coef=coef(lasso_lr_model)
coef
```
# lets filter the variable that have higher weight
```{r}
vars<- as.data.frame(as.matrix(coef))
library(tibble)
#options(scipen=999)
Vars1 <- tibble::rownames_to_column(vars, "Variable")
# first separate positive and negative cofficient
pos_var=subset(Vars1, s0>20)
neg_var=subset(Vars1, s0<=-20)
print(pos_var$Variable)
```
```{r}
print(neg_var$Variable)
```

# run the poisson regression with these variables
```{r}
set.seed(seed)
mla <- train(AADB ~speed_less_than_25+exist_bike_parking_q+pctwhite_q+pctbiketowork_h+pctnoveh_h+pct_low_wage+pctmedintensity_h+pctatleastbachelors_q+pctopenspace_t+slope
,
            
    #Stv_commute+Stv_leisure+pctbiketowork_q+totatleastbachelorspersqmi_h+log(totnovehpersqmi_h+0.01)+sqrt(hshldden#sitysqmi_t)+tertiary+speed_0_25
                data =data3, method = "glm",family='poisson',
                trControl = train_control5, na.action=na.exclude)
#family=sm.families.NegativeBinomial(link=sm.families.links.identity)
#family='poisson
# for nargative Binomial: family="nbinom2"
summarize_model(mla, data3, k, r)
plot_regions(mla, data3, title="CA Bicycle Exposure Static+Emerging Model", scales="fixed")  # scales="free" or 'fixed' is an option
plot_all(mla, data3, title="CA Bicycle Exposure Static+Emerging Model", label_outliers=NA)  # label outliers in top X%, NA turns off labeling
```

## Now run the Ridge Regression
```{r}
set.seed(1)
cv_ridge_lr_model1 = cv.glmnet(X, y, alpha = 0)
bestlam1 = cv_ridge_lr_model1$lambda.min
cv_ridge_lr_model1
par(mfrow=c(1,2))
fig(20, 8)
plot(cv_ridge_lr_model1)
plot(cv_ridge_lr_model1$glmnet.fit, 
     "lambda", label=FALSE)
```




```{r}
ridge_lr_model = glmnet(X, y, alpha =0, lambda = bestlam1)
coef_ridge=coef(ridge_lr_model)
coef_ridge
```


# lets filter the variable that have higher weight
```{r}
vars_ridge<- as.data.frame(as.matrix(coef_ridge))
#library(tibble)
#options(scipen=999)
Vars1_ridge <- tibble::rownames_to_column(vars_ridge, "Variable")
# first separate positive and negative cofficient
pos_var_ridge=subset(Vars1_ridge, s0>20)
neg_var_ridge=subset(Vars1_ridge, s0<=-20)
pos_var_ridge$Variable

```
```{r}
neg_var_ridge$Variable
```


# run the poisson regression with these selected variables by Ridge
```{r}
set.seed(seed)
m_ridge <- train(AADB ~ pctopenspace_t+pctmedintensity_h+pcthighintensity_h+pctwhite_t+pctatleastbachelors_q+pctbiketowork_h+pctnoveh_h+speed_less_than_20+slope+pct_high_wage+pctlowintensity_h+pctblack_h,
            
                data =data3, method = "glm",family='poisson',
                trControl = train_control5, na.action=na.exclude)
#family=sm.families.NegativeBinomial(link=sm.families.links.identity)
#family='poisson
# for nargative Binomial: family="nbinom2"
summarize_model(m_ridge, data3, k, r)
plot_regions(m_ridge, data3, title="CA Bicycle Exposure Static+Emerging Model", scales="fixed")  # scales="free" or 'fixed' is an option
plot_all(m_ridge, data3, title="CA Bicycle Exposure Static+Emerging Model", label_outliers=NA)  # label outliers in top X%, NA turns off labeling
```
```{r}
#if(!require("MASS")) install.packages("MASS")
#library(MASS)
```


# Run automated Forward and Backward Poisson regression model and see which variables work
```{r}
lr_model <- lm(AADB ~., data = data5)
summary(lr_model)
# it seems that 
```
```{r}
#https://www.kaggle.com/code/shilpagopal/variable-selection-stepwise-lasso-ridge-elasticnet
step_forward_lr_model <- stepAIC(lr_model, direction = "forward", trace = FALSE)
summary(step_forward_lr_model)
```

```{r}
step_backward_lr_model <- stepAIC(lr_model, direction = "backward", trace = FALSE)
summary(step_backward_lr_model)
```
```{r}
step_lr_model <- stepAIC(lr_model, direction = "both", trace = FALSE)
summary(step_lr_model)
```
# Now Make a model from this observations
```{r}
set.seed(seed)
options(digits=4)
options(scipen=999)
#options(digits=5)
spm <- train(AADB ~ empnum_density_q+near_univ_miles+forward_commute_trip_count+reverse_commute_trip_count+exist_bike_parking_q+pct_med_wage+pctbiketowork_t+log(hshlddensitysqmi_t+0.01)+pctatleastbachelors_q+totnovehpersqmi_q+speed_less_than_20+Total_road_Network_density+Intersection_density3+log(slope+0.01),
            
                data =data3, method = "glm",family='poisson',
                trControl = train_control5, na.action=na.exclude)
#family=sm.families.NegativeBinomial(link=sm.families.links.identity)
#family='poisson
# for nargative Binomial: family="nbinom2"
summarize_model(spm, data3, k, r)
plot_regions(spm, data3, title="CA Bicycle Exposure Static+Emerging Model", scales="fixed")  # scales="free" or 'fixed' is an option
plot_all(spm, data3, title="CA Bicycle Exposure Static+Emerging Model", label_outliers=NA)  # label outliers in top X%, NA turns off labeling
```
# Run the model based on Correlation value
```{r}
set.seed(seed)
mc <- train(AADB ~log(Stv_commute_adb+0.01)+log(Stv_leisure_adb+0.01)+pctbiketowork_q
+pctnoveh_h+popdensitysqmi_h
+log(slope+0.01)+totatleastbachelorspersqmi_h
+near_univ_miles+exist_bike_parking_q+pct_low_wage+Network_density3+Intersection_density5+pctlowintensity_h+pcthighintensity_h+Speed_25_or_Above+empnum_density_q+pctwhite_q+medhhincome_q
,
            
    #Stv_commute+Stv_leisure+pctbiketowork_q+totatleastbachelorspersqmi_h+log(totnovehpersqmi_h+0.01)+sqrt(hshldden#sitysqmi_t)+tertiary+speed_0_25
                data =data3, method = "glm",family='poisson',
                trControl = train_control5, na.action=na.exclude)
#family=sm.families.NegativeBinomial(link=sm.families.links.identity)
#family='poisson
# for nargative Binomial: family="nbinom2"
summarize_model(mc, data3, k, r)
plot_regions(mc, data3, title="CA Bicycle Exposure Static+Emerging Model", scales="fixed")  # scales="free" or 'fixed' is an option
plot_all(mc, data3, title="CA Bicycle Exposure Static+Emerging Model", label_outliers=NA)  # label outliers in top X%, NA turns off labeling
```




# Static+ Emerging Model
```{r}
# run combined  Static model (only)2016-2019)
set.seed(seed)
m1 <- train(AADB ~Stv_commute_adb+Stv_leisure_adb+pctbiketowork_q
+pctnoveh_h+popdensitysqmi_h+hshlddensitysqmi_h
+log(slope+0.01)
+near_univ_miles+path+residential+dist_ferry+exist_bike_parking_q+pct_low_wage+d1a+d3apo+d3b+d3bpo4+d5br+d5be+dist_water+pctlowintensity_h+speed_0_25+speed_21_35+speed_greater_than_35+path

,
            
    #Stv_commute+Stv_leisure+pctbiketowork_q+totatleastbachelorspersqmi_h+log(totnovehpersqmi_h+0.01)+sqrt(hshldden#sitysqmi_t)+tertiary+speed_0_25
                data =data3, method = "glm",family='poisson',
                trControl = train_control5, na.action=na.exclude)
#family=sm.families.NegativeBinomial(link=sm.families.links.identity)
#family='poisson
# for nargative Binomial: family="nbinom2"
summarize_model(m1, data3, k, r)
plot_regions(m1, data3, title="CA Bicycle Exposure Static+Emerging Model", scales="fixed")  # scales="free" or 'fixed' is an option
plot_all(m1, data3, title="CA Bicycle Exposure Static+Emerging Model", label_outliers=NA)  # label outliers in top X%, NA turns off labeling
```


```{r}
nrow(data)
```


```{r}
m1$pred
```


```{r}
min(m1$pred[2])
```



```{r}
data5=merge(data3,m1$pred, by='rowIndex')
head(data5,5)
```

```{r}
mpred=aggregate(pred~tdg_id+year+Leg+county+Lat+Long+geometry+obs+rowIndex,data=data5, FUN=mean)
head(mpred,5)
```

```{r}
write.csv(mpred, 'D:/Bike Exposure/Modeling/Poisson_Regression_model_outcomes_july23_AADBT.csv')
```


```{r}
per=subset(data, type=='eco_permanent')
length(unique(per$ID))
short=subset(data, type=='short_term')
length(unique(short$tdg_id))
length(unique(short$Lat))
length(unique(short$Long))

```



```{r}
ggplot(mpred, aes(x=pred, y=obs, col=as.factor(county),
                    shape=as.factor(county))) +
    geom_abline(intercept=0, slope=1, lty=2) +
    geom_point(size=1.0, fill=NA) +coord_flip(ylim = c(0,3300), xlim = c(0, 3300))+
    labs(x="Mean predicted AADBT", y="Observed AADBT")+scale_shape_manual(values=seq(0,31))

ggtitle(title)

```


# Prepare SHS system data for model application
```{r}
shs=read.csv('D:/Bike Exposure/Modeling/smart4_final_output_Jun29_2023.csv')
shs$primary <- ifelse(shs$fclass=='primary', 1, 0)
shs$secondary <- ifelse(shs$fclass=='secondary', 1, 0)
shs$tertiary<- ifelse(shs$fclass=='tertiary', 1, 0)
shs$residential<- ifelse(shs$fclass=='residential', 1, 0)
shs$trunk<- ifelse(shs$fclass=='trunk', 1, 0)
shs$secondary_link<- ifelse(shs$fclass=='secondary_link', 1, 0)
shs$unclassified<- ifelse(shs$fclass=='unclassified', 1, 0)
shs$speed_0_25=ifelse(shs$speed<=25, 1, 0)
shs$speed_21_35=ifelse(dplyr::between(shs$speed, 21, 35), 1, 0)
shs$speed_greater_than_35=ifelse(shs$speed>35, 1, 0)
shs$Stv_commute_adb=(shs$forward_commute_trip_count+shs$reverse_commute_trip_count)/365
shs$Stv_leisure_adb=(shs$forward_leisure_trip_count+shs$reverse_leisure_trip_count)/365
shs$Stv_Ave_speed=shs$forward_average_speed+shs$reverse_average_speed
shs$path=ifelse(shs$bike_facs=='Class I', 1, 0)
shs$bike_lane=ifelse(shs$bike_facs=='Class II', 1, 0)
shs$bike_route=ifelse(shs$bike_facs=='Class III', 1, 0)
shs$cycle_track=ifelse(shs$bike_facs=='Class IV', 1, 0)
shs$trail=ifelse(shs$bike_facs=='Class V', 1, 0)
shs$other=ifelse(shs$bike_facs=='Class VI', 1, 0)
shs$Interstate=ifelse(shs$fc_draft==1, 1, 0)
shs$Freeway=ifelse(shs$fc_draft==2, 1, 0)
shs$Principal_Arterial=ifelse(shs$fc_draft==3, 1, 0)
shs$Minor_Arterial=ifelse(shs$fc_draft==4, 1, 0)
shs$Major_Collector=ifelse(shs$fc_draft==5, 1, 0)
shs$Minor_Collector=ifelse(shs$fc_draft==6, 1, 0)
shs$Local=ifelse(shs$fc_draft==7, 1, 0)
write.csv(shs,'D:/Bike Exposure/Modeling/SHS_application_data_july12.csv')
```

